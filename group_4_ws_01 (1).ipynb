{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BAN200 Week 01 Homework"
      ],
      "metadata": {
        "id": "tDdPniKEu7ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To complete the homework you will need to modify this template by adding Python code and/or text.\n",
        "\n",
        "Before starting the homework, make sure to save a copy of this template to your personal Google Drive. If you haven't saved your own copy, any changes you make will be lost when you close your browser window.\n",
        "\n",
        "To submit your homework: go to \"File\" in the Colab menu bar > select \"Download\" > select \"Download .ipynb\". This will download a \".ipynb\" file to your computer. You must submit this file.\n",
        "\n",
        "The homework is to be completed in groups. It is due at the start of next class.\n",
        "\n",
        "Homework is graded on the following scale:\n",
        "\n",
        "* *100%* -- The assignment was submitted on time, any code runs without errors, and every question is answered correctly.\n",
        "\n",
        "* *80%* -- The assignment was submitted on time, any code runs without errors, and every question is answered. Some questions may be incorrect, but the submission demonstrates an average level of effort and average level of understanding of the material.\n",
        "\n",
        "* *60%* -- The submission demonstrates a below-average level of effort and below-average level of understanding of the material. This is the highest grade that should be given to submissions that are submitted late, have code that throws uncaught errors, or leave some questions unanswered.\n",
        "\n",
        "* *0%* -- No assignment was submitted, or the submission demonstrates little-to-no effort and little-to-no understanding of the material."
      ],
      "metadata": {
        "id": "Ebn9PTsc6C3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "tYcvY8gEwszK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzZm6nIyVH7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
        "```\n",
        "I love McDonalds!\n",
        "```\n",
        "Your list should be stored in a variable `tweet_0`."
      ],
      "metadata": {
        "id": "XXLVXlwxvQAu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhuYLJ9ru3UY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99dc1120-db2f-45b7-e9cb-cedd86ff8561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I love McDonalds!']\n"
          ]
        }
      ],
      "source": [
        "# put your answer here\n",
        "tweet_0=[\"I love McDonalds!\"]\n",
        "print(tweet_0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "Gs8s0KVfwvPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
        "```\n",
        "McDonalds: you are so good ...\n",
        "```\n",
        "Your list should be stored in a variable `tweet_1`."
      ],
      "metadata": {
        "id": "sibMSRSkwvZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "tweet_1=[\"McDonalds: you are so good ...\"]\n",
        "print(tweet_1)"
      ],
      "metadata": {
        "id": "DPR15yQRxNm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1792d0cb-0843-4f0f-bc33-ae59936c491f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['McDonalds: you are so good ...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "vuhYPiUjyZqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
        "```\n",
        "This McDonalds hamburger, it is gross\n",
        "```\n",
        "Your list should be stored in a variable `tweet_2`."
      ],
      "metadata": {
        "id": "Nh2axebEyZqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "tweet_2=[\"This McDonalds hamburger, it is gross\"]\n",
        "print(tweet_2)"
      ],
      "metadata": {
        "id": "RAGTbXTPyZqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06f48a6-ccca-4e2f-f6e5-38085a23b26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This McDonalds hamburger, it is gross']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "rJXKnNWG_Zdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represent this lexicon as a Python dictionary called `lexicon`:\n",
        "\n",
        "```\n",
        "+2.1  love\n",
        "+1.8  good\n",
        "-1.5  gross\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nR2dofHV_dge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "lexicon={\"love\":2.1, \"good\":1.8, \"gross\":-1.5}\n",
        "print(lexicon)"
      ],
      "metadata": {
        "id": "DUFEM1dpA6VQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eff684a-4ed4-4337-a717-d69130aac2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'love': 2.1, 'good': 1.8, 'gross': -1.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "ozA3GUqDzXpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a for loop to iterate over all of the tokens in `tweet_2` and make them lower case."
      ],
      "metadata": {
        "id": "CzJ1Ht1-zZw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "for i in tweet_2:\n",
        "  print(i.lower())"
      ],
      "metadata": {
        "id": "4prOUtnDzaOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f3aaa8-1934-467c-f80b-829d086fba6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this mcdonalds hamburger, it is gross\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6"
      ],
      "metadata": {
        "id": "JwM5Sph5BbYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a for loop to calculate a sentiment score for `tweet_2` using `lexicon`."
      ],
      "metadata": {
        "id": "BtSJ-32yBbYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "tweet_2=\"this mcdonalds hamburger, it is gross\"\n",
        "tweet_2=tweet_2.split()\n",
        "\n",
        "lexicon={\"love\":2.1, \"good\":1.8, \"gross\":-1.5}\n",
        "\n",
        "score = 0\n",
        "for token in tweet_2:\n",
        "  if token in lexicon:\n",
        "    score = score+ lexicon[token]\n",
        "\n",
        "print(\"Sentiment score:\", score)\n"
      ],
      "metadata": {
        "id": "ykReYpiwBbYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b033f6f9-e355-4820-f7f3-532b5fa449fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment score: -1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7"
      ],
      "metadata": {
        "id": "DBZ1DuR0B0LN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function that takes two parameters -- a list of tokens and a lexicon -- and returns a sentiment score. Test-out your function with `tweet_2`."
      ],
      "metadata": {
        "id": "Eak51Y5gB0LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "def calculate_sentiment_score(tokens, lexicon):\n",
        "  score=0\n",
        "  for token in tokens:\n",
        "    if token in lexicon:\n",
        "      score = score + lexicon[token]\n",
        "      return score\n",
        "sentiment_score=calculate_sentiment_score(tweet_2,lexicon)\n",
        "print(\"Sentiment score:\", sentiment_score)"
      ],
      "metadata": {
        "id": "CD_9162rB0LP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b91ae4-c775-496e-e3f2-e8c14934ae8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment score: -1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8"
      ],
      "metadata": {
        "id": "tzp8AShL02T7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function that takes a list of tokens as a paramater and makes them lower case. You can repurpose your code from Question 5. Test-out your function with `tweet_1`."
      ],
      "metadata": {
        "id": "Eu1GJe7Z04RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import Break\n",
        "# put your answer here\n",
        "tweet_1=\"McDonalds: you are so good ...\"\n",
        "def lowercase_function(tokens):\n",
        "  for token in tokens:\n",
        "    print(tokens.lower())\n",
        "    break\n",
        "\n",
        "lower_tweet_1=lowercase_function(tweet_1)\n",
        "print(lower_tweet_1)"
      ],
      "metadata": {
        "id": "I2j6XV3003eK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd09938-5146-4507-f979-c658b07a8be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mcdonalds: you are so good ...\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 9"
      ],
      "metadata": {
        "id": "XbyMF6StxQm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new variable `corpus` that stores the three earlier tweets in a \"list of lists\"."
      ],
      "metadata": {
        "id": "brjrHomcxR3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "tweet_0 = \"I love McDonalds!\"\n",
        "tweet_1 = \"McDonalds: you are so good ...\"\n",
        "tweet_2 = \"This McDonalds hamburger, it is gross\"\n",
        "\n",
        "tokens_0 = tweet_0.split()\n",
        "tokens_1 = tweet_1.split()\n",
        "tokens_2 = tweet_2.split()\n",
        "\n",
        "corpus = [tokens_0, tokens_1, tokens_2]\n",
        "\n",
        "print(corpus)"
      ],
      "metadata": {
        "id": "p0D9k0XdzRUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1168eea-16d3-4c39-cc27-41e1b7a62568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['I', 'love', 'McDonalds!'], ['McDonalds:', 'you', 'are', 'so', 'good', '...'], ['This', 'McDonalds', 'hamburger,', 'it', 'is', 'gross']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10"
      ],
      "metadata": {
        "id": "8-6RVuSm-knj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a for loop to iterate over all of the tweets in `corpus` and use your function from Question 8 to make all of the tokens lowercase."
      ],
      "metadata": {
        "id": "obzpKZnn-lv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "\n",
        "def convert_tokens_to_lowercase(tokens):\n",
        "    lowercase_tokens = [token.lower() for token in tokens]\n",
        "    return lowercase_tokens\n",
        "\n",
        "for i in range(len(corpus)):\n",
        "    corpus[i] = convert_tokens_to_lowercase(corpus[i])\n",
        "\n",
        "print(corpus)\n"
      ],
      "metadata": {
        "id": "nVPLGpPo-00p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d7e087-0686-494d-ea68-bd2b77a4d223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'love', 'mcdonalds!'], ['mcdonalds:', 'you', 'are', 'so', 'good', '...'], ['this', 'mcdonalds', 'hamburger,', 'it', 'is', 'gross']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 11"
      ],
      "metadata": {
        "id": "0zZUcayuCh3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a for loop and your function from Question 7 to print-out scores for each tweet."
      ],
      "metadata": {
        "id": "S_1GxD65CjRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "\n",
        "def calculate_sentiment_score(tokens, lexicon):\n",
        "  score=0\n",
        "  for token in tokens:\n",
        "    if token in lexicon:\n",
        "      score = score + lexicon[token]\n",
        "      return score\n",
        "\n",
        "\n",
        "\n",
        "tweet_0 = \"I love McDonalds!\"\n",
        "tweet_1 = \"McDonalds: you are so good ...\"\n",
        "tweet_2 = \"This McDonalds hamburger, it is gross\"\n",
        "\n",
        "tweets=[tweet_0,tweet_1,tweet_2]\n",
        "\n",
        "for index,i in enumerate(tweets):\n",
        "  tokens=i.split()\n",
        "  sentiment_score=calculate_sentiment_score(tokens,lexicon)\n",
        "  print(f\"Sentiment score of tweet {index} is\", sentiment_score)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5O9AvoNSCtdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b44038-6a59-4e4a-f190-575b8b86a2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment score of tweet 0 is 2.1\n",
            "Sentiment score of tweet 1 is 1.8\n",
            "Sentiment score of tweet 2 is -1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 12"
      ],
      "metadata": {
        "id": "glJVQiVyDjbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use your function from Question 7 to score the tweet `McDonalds is not great`."
      ],
      "metadata": {
        "id": "H-5hmNnhDlez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here\n",
        "review=\"McDonalds is not great\"\n",
        "review_split=review.split()\n",
        "\n",
        "def calculate_sentiment_score(tokens, lexicon):\n",
        "  score=0\n",
        "  for token in tokens:\n",
        "    if token in lexicon:\n",
        "      score = score + lexicon[token]\n",
        "      return score\n",
        "sentiment_score=calculate_sentiment_score(review_split,lexicon)\n",
        "print(\"Sentiment score:\", sentiment_score)"
      ],
      "metadata": {
        "id": "ekJKKy3nDkrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38820df0-ada5-4c27-f6ae-187a402727fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment score: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 13"
      ],
      "metadata": {
        "id": "4RYUnxt1DuBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In one or two sentences, explain the pros and cons of our sentiment model."
      ],
      "metadata": {
        "id": "wg8XyVSLEA28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sentiment model prvides a clear way to show the sentiment results on textual data, and allow us to have a better understanding of the whole dataset if comprehensive model is deployed.\n",
        "\n",
        "However, the lexicon from the model is manually established, there might be possibilities of not including enough sentiment tokens and resulting in inaccuracies in the sentiment assessment.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YWgyXs_yv2N0"
      }
    }
  ]
}